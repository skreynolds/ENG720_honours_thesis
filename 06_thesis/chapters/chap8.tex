\chapter{Conclusion and Future Directions}

Load frequency control is an important part of the AGC scheme for a power system. Stochastic load demand profiles, arising as a result of power consuming appliances being added or removed from the network, cause power system frequency changes. Utility providers seek to mitigate these frequency changes by modifying power generation in real time. Traditionally this is done using classical control architectures such as PI controllers. More recently, the use of alternative control architectures have been explored with useful results being demonstrated for fuzzy logic controllers, and genetic algorithms used for online turning of PI parameters. Control using neural networks has also been explored, but with limited success.

This research sought to understand the viability of using a neural network, trained using a deep reinforcement learning algorithm, for load frequency control. The research focused on the DDPG algorithm which was found to suitable for problems involving robotics, and applications with continuous control actuation. A temporal model of a two area power system was developed in the temporal domain, and was implemented as part of a software stack that included neural network architectures, demand signals, and the DDPG algorithm.

Several experiments were performed using different settings for the DDPG algorithm, and different neural network architectures. These experiments saw agents trained on the load frequency control problem for a two area power system for 10000 episodes. Training results demonstrated that the DDPG algorithm was able to train a neural network for the task of load frequency control. Learning was rapid during the first 1000 episodes of training. Although learning continued in the later stages of training, progress was observed to plateau. Agent control learning was generally observed to converge on a policy after episode 7000.

Trained agent performance was measured across metrics including cumulative reward, maximum absolute changes for frequency and control strength, average absolute change for frequency and control strength, and settling times. Trained agent performance was evaluated with a number of independent trials using positive and negative step changes at various times throughout a 30 sec simulation duration and compared to the performance of a PI controller optimally tuned for the same task.

All trained neural networks were able to show frequency control performance for a two area power system under step change disturbances. This was true for every scenario tested. The best controller was an original architecture from Lillicrap \textit{et alias} that was used as a baseline. This controller was able to maintain frequency deviations in Area 1 within an envelope of 1.63\% of the frequency signal (0.0163 Hz pu). The worst controller had an envelope of 4.21\% or (0.0421 Hz pu).

Despite this result, the PI controller was able to perform load frequency control better than trained neural networks. This was true when compared to the performance for all experiments. PI controller dominance was demonstrated almost unanimously across all performance metrics, with notable exceptions being the maximum frequency deviations and settling times. Three agents developed policies closely resembling the performance of a PI controller. These were from the Baseline, OU Noise, and Stochastic Load Demand experiments. A visual inspection of the controller performance for each of these experiments revealed a number of defects such as unstable oscillations in control signals or persistant frequency offsets from the zero point which ultimately rendered the control policies unusable.

Given the close proximity of neural network policies to the optimally tuned PI controller performance continued investigation into the problem is warranted. It has been noted that prior to further investigation the reward structure should be examined to ensure it is suitable for the load frequency control task. Moreover the software stack should be independently re-developed and verified against the existing software stack. Future work should seek to modify DDPG algorithms, or the neural network architecture, for increased neural network performance. Alternatively, a different deep reinforcement learning algorithm could be applied to the problem. Should further failures occur in attempts to develop neural networks for load frequency control, a mathematical analysis of the problem should be undertaken to ascertain if load frequency control using a neural network is possible.