\begin{table}[h]
	\centering
	\caption{Experiment C details of environment reward function and termination conditions, DDPG algorithm OU noise settings, and a comparison of trained DDPG agent performance compared to an optimal PI controller.}
	\begin{tabular}{@{\extracolsep{6pt}}cp{2.8cm}p{2.8cm}p{2.8cm}p{2.8cm}}
		\toprule
		\multirow{12}{*}{\rotatebox[origin=c]{90}{\LARGE \textbf{Experiment C}}} & \multicolumn{4}{c}{\textbf{Reward Function}}  \\
		 \rule{0pt}{1.5ex}
		 & \multicolumn{4}{l}{At each time step the agent received a reward of:} \\[0.1cm]
		 & \multicolumn{4}{c}{\small$\begin{aligned}\texttt{r} = &- |\texttt{frequency 1}| - |\texttt{frequency 2}| \\ &- |\texttt{tieline}| \\ &- |\texttt{control signal 1}| - |\texttt{control signal 2}|\end{aligned}$}\\[-0.35cm]
		 & & & & \\
		\cline{2-5}\rule{0pt}{2.5ex}
		 & \multicolumn{2}{c}{\textbf{OU Noise}} & \multicolumn{2}{c}{\textbf{Results}}\\
		\cline{2-3}\cline{4-5}\rule{0pt}{2.5ex}
		 & $\mu$ 	& 0.00 & PI   & -38.24 \\
		 & $\theta$ & 0.15 & DDPG & -408.72 \\
		 & $\sigma$ & 0.20 & & \\
		 \cline{2-5}\rule{0pt}{2.5ex}  
		 & \multicolumn{4}{c}{\textbf{Termination Condition}}\\
		 & \multicolumn{4}{p{12cm}}{Episode terminated when the episode reached 30 sec}\\
		 \toprule
	\end{tabular}
\end{table}