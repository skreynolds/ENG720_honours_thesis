% These \phantomsection are to ensure that the hyperref package hyperlinks to the correct page in the electronic pdf. If you turn hyperref off they don't do anything so they can just stay here.
\phantomsection\addcontentsline{toc}{chapter}{Abstract}
\chapter*{Abstract} % Starred chapter=chapter with no number.
Power systems behave in a non-linear fashion; however, traditional control architectures for maintaining power system frequency are designed assuming that plant can be modelled using ordinary linear differential equations. This assumption is reasonable for minor frequency deviations given the present level of non-linearity in power systems. Owing to an increase in the proportion of photovoltaic power generation, along with an increase in the use of battery energy storage systems, Australian power system dynamics are becoming increasingly non-linear. This is creating a need to explore novel control architectures to improve frequency control performance.

Reinforcement learning (RL) can be used to design controllers. Through trial and error, the RL agent learns what actions it must take to achieve a control objective. It does this with no prior knowledge of the system it is trying to control. This makes RL ideal when designing controllers for complex non-linear systems that are difficult to mathematically model. In the past, RL has been successfully applied to problems with low dimensional discrete state and action spaces. In the last five years, the integration of deep neural networks as function approximators in RL architectures has demonstrated impressive performance for control problems with high dimensional continuous state and action spaces. This approach is known as deep reinforcement learning (DRL), and is considered state-of-the-art for robotic applications.

This work applies a Deep Deterministic Policy Gradient (DDPG) DRL algorithm as a controller for the system frequency and transmission line power flow for a two-area power system. Each area is comprised of a single generator and a single load that is representative of aggregated generation and aggregated load demand for the respective areas. A single transmission line connects the two areas. Load demand for each power area fluctuates as consumers switch appliances on and off. If left unchecked this causes deviations of the system frequency away from 50$\si{\hertz}$. Using a simulated power system model and load demand data sourced from a utility provider, the DDPG agent will be trained to control a regulating generator. Its control action can arrest frequency deviations, and restore each area to the scheduled value, under normal operating conditions.

The performance of the DDPG controller has been evaluated against classical control approaches to provide an assessment of the viability of DRL controllers for power system control.